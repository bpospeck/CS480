








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <script type="text/javascript">
//<![CDATA[
try{if (!window.CloudFlare) {var CloudFlare=[{verbose:0,p:0,byc:0,owlid:"cf",bag2:1,mirage2:0,oracle:0,paths:{cloudflare:"/cdn-cgi/nexp/dok3v=1613a3a185/"},atok:"2c554000d27230245b2f6639f086e6b3",petok:"733caa6aecd41c7c1091ba00c1387f337ee9fa02-1490566653-1800",zone:"jupyter.org",rocket:"0",apps:{"ga_key":{"ua":"UA-52617120-1","ga_bs":"2"}}}];!function(a,b){a=document.createElement("script"),b=document.getElementsByTagName("script")[0],a.async=!0,a.src="//ajax.cloudflare.com/cdn-cgi/nexp/dok3v=f2befc48d1/cloudflare.min.js",b.parentNode.insertBefore(a,b)}()}}catch(e){};
//]]>
</script>
<link href="/static/build/styles.css?v=c18d49652a516277e15114bbd447f1c1" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png?v=5a3c9ede93e2a8b8ea9e3f8f3da1a905">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png?v=45d86fc8f24dc00638035e1dd7a6d898">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png?v=540b5eb0f3cfd25f1439d1c9bd30e15f">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png?v=225f0590e187e1458625654f10a28f56">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.ipython.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css?v=d05748bef7d8f0edbc1e0133b9a41fe0" rel="stylesheet">
  

  

  
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

<script type="text/javascript">
/* <![CDATA[ */
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-52617120-1']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

(function(b){(function(a){"__CF"in b&&"DJS"in b.__CF?b.__CF.DJS.push(a):"addEventListener"in b?b.addEventListener("load",a,!1):b.attachEvent("onload",a)})(function(){"FB"in b&&"Event"in FB&&"subscribe"in FB.Event&&(FB.Event.subscribe("edge.create",function(a){_gaq.push(["_trackSocial","facebook","like",a])}),FB.Event.subscribe("edge.remove",function(a){_gaq.push(["_trackSocial","facebook","unlike",a])}),FB.Event.subscribe("message.send",function(a){_gaq.push(["_trackSocial","facebook","send",a])}));"twttr"in b&&"events"in twttr&&"bind"in twttr.events&&twttr.events.bind("tweet",function(a){if(a){var b;if(a.target&&a.target.nodeName=="IFRAME")a:{if(a=a.target.src){a=a.split("#")[0].match(/[^?=&]+=([^&]*)?/g);b=0;for(var c;c=a[b];++b)if(c.indexOf("url")===0){b=unescape(c.split("=")[1]);break a}}b=void 0}_gaq.push(["_trackSocial","twitter","tweet",b])}})})})(window);
/* ]]> */
</script>
</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js?v=e071abda8fe61194711cfc2ab99fe104"></script>
  <script src="/static/components/requirejs/require.js?v=6da8be361b9ee26c5e721e76c6d4afce"></script>
  <script src="/static/components/moment/min/moment.min.js?v=89f87298ad94aa1e6b92f42eb66da043"></script>

<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg?v=479cefe8d932fb14a67b93911b97d70f" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="http://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
      
        <li>
    <a href="/format/script/url/www.cs.colostate.edu/~anderson/cs480/notebooks/15%20Classification%20with%20Linear%20Logistic%20Regression.ipynb" title="View as Code" >
      <span class="fa fa-code fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  
    
  

  
    <li>
    <a href="#" title="Python [default] Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python [default] Kernel</span>
    </a>
  </li>
  

  

  <li>
    <a href="http://www.cs.colostate.edu/%7Eanderson/cs480/notebooks/15%20Classification%20with%20Linear%20Logistic%20Regression.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <div id="notebook">
    <div id="notebook-container">
      
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\newcommand{\xv}{\mathbf{x}}
\newcommand{\Xv}{\mathbf{X}}
\newcommand{\yv}{\mathbf{y}}
\newcommand{\Yv}{\mathbf{Y}}
\newcommand{\zv}{\mathbf{z}}
\newcommand{\av}{\mathbf{a}}
\newcommand{\Wv}{\mathbf{W}}
\newcommand{\wv}{\mathbf{w}}
\newcommand{\betav}{\mathbf{\beta}}
\newcommand{\gv}{\mathbf{g}}
\newcommand{\Hv}{\mathbf{H}}
\newcommand{\dv}{\mathbf{d}}
\newcommand{\Vv}{\mathbf{V}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\tv}{\mathbf{t}}
\newcommand{\Tv}{\mathbf{T}}
\newcommand{\Sv}{\mathbf{S}}
\newcommand{\zv}{\mathbf{z}}
\newcommand{\Zv}{\mathbf{Z}}
\newcommand{\Norm}{\mathcal{N}}
\newcommand{\muv}{\boldsymbol{\mu}}
\newcommand{\sigmav}{\boldsymbol{\sigma}}
\newcommand{\phiv}{\boldsymbol{\phi}}
\newcommand{\Phiv}{\boldsymbol{\Phi}}
\newcommand{\Sigmav}{\boldsymbol{\Sigma}}
\newcommand{\Lambdav}{\boldsymbol{\Lambda}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\argmax}[1]{\underset{#1}{\operatorname{argmax}}}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}}}
\newcommand{\dimensionbar}[1]{\underset{#1}{\operatorname{|}}}
\newcommand{\dimensionbar}[1]{\underset{#1}{\operatorname{|}}}
\newcommand{\grad}{\mathbf{\nabla}}
\newcommand{\ebx}[1]{e^{\wv_{#1}^T \xv_n}}
\newcommand{\eby}[1]{e^{y_{n,#1}}}
\newcommand{\Tiv}{\mathbf{Ti}}
\newcommand{\Fv}{\mathbf{F}}
\newcommand{\ones}[1]{\mathbf{1}_{#1}}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Classification-with-Linear-Logistic-Regression">Classification with Linear Logistic Regression<a class="anchor-link" href="#Classification-with-Linear-Logistic-Regression">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Motivation-and-Setup">Motivation and Setup<a class="anchor-link" href="#Motivation-and-Setup">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Recall that a linear model used for classification can result in masking. We discussed fixing this by using different
shaped membership functions, other than linear.</p>
<p>Our first approach to this was to use generative models (Normal distributions) to model the data
from each class, forming $p(\xv|C=k)$.  Using Bayes Theorem, we converted this to $p(C=k|\xv)$ and
derived QDA and LDA.</p>
<p>Now we will derive a linear model that directly predicts $p(C=k|\xv)$, resulting in the algorithm called logisitic
regression.  It is derived to maximize the likelihood of the data, given a bunch of samples and their class labels.</p>
<p>Remember this picture?</p>
<p>&lt;img src="<a href="http://www.cs.colostate.edu/~anderson/cs480/notebooks/indicatorvarsmax2.png">http://www.cs.colostate.edu/~anderson/cs480/notebooks/indicatorvarsmax2.png</a>" width=400&gt;</p>
<p>The problem was that the green line for Class 2 was too low.
In fact, all lines are too low in the middle of x range.  Maybe we
can reduce the masking effect by</p>
<ul>
<li>requiring the function values to be between 0 and 1, and</li>
<li>requiring them to sum to 1 for every value of x.</li>
</ul>
<p>We can satisfy those two requirements by directly representing
$p(C=k|\xv)$ as</p>
$$
    \begin{align*}
      p(C=k|\xv) = \frac{f(\xv;\wv_k)}{\sum_{m=1}^K f(\xv;\wv_m)}
    \end{align*}
$$<p>with $f(\xv;\wv) \ge 0$. We haven't discussed the form of $f$ yet, but $\wv$
represents the parameters of $f$ that we will tune to fit the
training data (later).</p>
<p>This is certainly an expression that is between 0 and 1 for
any $\xv$.
And we have $p(C=k|\xv)$ expressed directly, as opposed to
the previous generative approach of first modeling $p(\xv|C=k)$
and using Bayes' theorem to get $p(C=k|\xv)$.</p>
<p>Let's give the above expression another name</p>
$$
    \begin{align*}
      g_k(\xv) = p(C=k|\xv) = \frac{f(\xv;\wv_k)}{\sum_{m=1}^K f(\xv;\wv_m)}
    \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Derivation">Derivation<a class="anchor-link" href="#Derivation">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Whatever we choose for $f$, we must make a plan for
optimizing its parameters $\wv$.  How?</p>
<p>Let's maximize the likelihood of the data.  So, what is the
likelihood of training data consisting of samples $\{\xv_1, \xv_2, \ldots, \xv_N\}$ and class indicator variables</p>
$$
  \begin{align*}
    \begin{pmatrix}
      t_{1,1} & t_{1,2} & \ldots & t_{1,K}\\
      t_{2,1} & t_{2,2} & \ldots & t_{2,K}\\
      \vdots\\
      t_{N,1} & t_{N,2} & \ldots & t_{N,K}
    \end{pmatrix}
  \end{align*}
$$<p>with every value $t_{n,k}$ being 0 or 1, and each row of this matrix
contains a single 1? (We can also express $\{\xv_1, \xv_2,
\ldots, \xv_N\}$ as an $N \times D$ matrix, but we will be using
single samples $\xv_n$ more often in the following.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Likelihood">Data Likelihood<a class="anchor-link" href="#Data-Likelihood">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The likelihood is just the product of all $p(C=\text{class of }
n^\text{th}\text{ sample}\,|\,\xv_n)$ values
for sample $n$.  A common way to express this product, using those handy indicator variables is</p>
$$
    \begin{align*}
      L(\betav) = \prod_{n=1}^N \prod_{k=1}^K p(C=k\,|\, \xv_n)^{t_{n,k}}
    \end{align*}
$$<p>Say we have three classes ($K=3$) and training sample $n$ is from Class 2, then the  product is</p>
$$
      \begin{align*}
        p(C=1\,|\,\xv_n)^{t_{n,1}} p(C=2\,|\,\xv_n)^{t_{n,2}}
        p(C=3\,|\,\xv_n)^{t_{n,3}} & = 
         p(C=1\,|\,\xv_n)^0 p(C=2\,|\,\xv_n)^1 p(C=3\,|\,\xv_n)^0 \\
        & = 1\; p(C=2\,|\,\xv_n)^1 \; 1 \\
        & = p(C=2\,|\,\xv_n) 
      \end{align*}
$$<p>This shows how the indicator variables as exponents select the correct terms to be included in the product.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Maximizing-the-Data-Likelihood">Maximizing the Data Likelihood<a class="anchor-link" href="#Maximizing-the-Data-Likelihood">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, we want to find $\wv$ that maximizes the data likelihood.  How shall we proceed?</p>
$$
    \begin{align*}
      L(\wv) & = \prod_{n=1}^N \prod_{k=1}^K p(C=k\,|\, \xv_n) ^ {t_{n,k}}
    \end{align*}
$$<p>Right.  Find the derivative with respect to each component of $\wv$, or the gradient with respect to $\wv$.  But there is
a mess of products in this. So...</p>
<p>Right again.  Work with the natural logarithm  $\log L(\wv)$ which we will call $LL(\wv)$.</p>
$$
    \begin{align*}
      LL(\wv) = \log L(\wv) = \sum_{n=1}^N \sum_{k=1}^K t_{n,k}  \log p(C=k\,|\,\xv_n)
    \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gradient-Ascent">Gradient Ascent<a class="anchor-link" href="#Gradient-Ascent">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Unfortunately, the gradient of $LL(\wv)$ with respect to
$\wv$ is not linear in $\wv$, so we cannot simply set the
result equal to zero and solve for $\wv$.</p>
<p>Instead, we do gradient ascent. (Why "ascent"?)</p>
<ul>
<li>Initialize $\wv$ to some value.</li>
<li>Make small change to $\wv$ in the direction of the  gradient of $LL(\wv)$ with respect to $\wv$  (or $\grad_{\wv} LL(\wv)$)</li>
<li>Repeat above step until $LL(\wv)$ seems to be at a maximum.</li>
</ul>
$$
      \begin{align*}
        \wv \leftarrow \wv + \alpha \grad_{\wv} LL(\wv)
      \end{align*}
$$<p>where $\alpha$ is a constant that affects the step size.</p>
<p>Remember that $\wv$ is a matrix of parameters, with, let's
say, columns corresponding to the values required for each $f$, of
which there are $K-1$.</p>
<p>We can work on the update formula and $\grad_{\wv} LL(\wv)$ one column at
a time</p>
$$
    \begin{align*}
        \wv_k  \leftarrow \wv_k + \alpha \grad_{\wv_k} LL(\wv)
    \end{align*}
$$<p>and combine them at the end.</p>
$$
    \begin{align*}
        \wv  \leftarrow \wv + \alpha (\grad_{\wv_1} LL(\wv),
        \grad_{\wv_2} LL(\wv), \ldots, \grad_{\wv_{K-1}} LL(\wv))
    \end{align*}
$$<p>Remembering that $\frac{\partial \log h(x)}{\partial x} = \frac{1}{h(x)}\frac{\partial h(x)}{x}$ and
that $p(C=k|\xv_n) = g_k(\xv_n)$</p>
$$
      \begin{align*}
      LL(\wv) & = \sum_{n=1}^N \sum_{k=1}^K  t_{n,k} \log p(C=k\,|\,\xv_n)\\
      & = \sum_{n=1}^N \sum_{k=1}^K t_{n,k} \log g_k(\xv_n)\\
      \grad_{\wv_j} LL(\wv) & = \sum_{n=1}^N \sum_{k=1}^K
      \frac{t_{n,k}}{g_k(\xv_n)} \grad_{\wv_j} g_k(\xv_n)
      \end{align*}
$$<p>It would be super nice if $\grad_{\wv_j} g_k(\xv_n)$
includes the factor $g_k(\xv_n)$ so that it will cancel
with the $g_k(\xv_n)$ in the denominator.</p>
<p>Can get this by defining</p>
$$
    \begin{align*}
      f(\xv_n;\wv_k) & = \ebx{k} \;\;\;\;\text{ so}\\
      g_k(\xv_n) & = \frac{f(\xv_n;\wv_k)}{\sum_{m=1}^{K} f(\xv_n;\wv_m)}
    \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can work on $\grad_{\wv_j} g_k(\xv_n)$.</p>
$$
\begin{align*}
g_k(\xv_n) = \frac{\ebx{k}}{\sum_{m=1}^{K} \ebx{m}}
\end{align*}
$$<p>So</p>
$$
    \begin{align*}
      \grad_{\wv_j} g_k(\xv_n) & = \grad_{\wv_j} \left (\frac{\ebx{k}}{\sum_{m=1}^{K} \ebx{m}} \right )\\
    & = \grad_{\wv_j} \left [ \left (\sum_{m=1}^{K} \ebx{m} \right )^{-1} \ebx{k} \right ] 
    \end{align*}
$$<p>Since
$$
\begin{align*}
\grad_{\wv_j} \ebx{k} &= \begin{cases}
\xv_n \ebx{k}, & \text{if } k=j\\
0 & \text{otherwise}
\end{cases}
\end{align*}
$$
and
$$
\begin{align*}
\grad_{\wv_j} \sum_{m=1}^K-1 \ebx{m} &= \xv_n \ebx{k}
\end{align*}
$$
then
$$
    \begin{align*}
      \grad_{\wv_j} g_k(\xv_n) & = \grad_{\wv_j} \left (\frac{\ebx{k}}{\sum_{m=1}^{K} \ebx{m}} \right )\\
    & = -1 \left (\sum_{m=1}^{K} \ebx{m} \right )^{-2} \xv_n \ebx{j}
    \ebx{k} + \left (\sum_{m=1}^{K} \ebx{m} \right )^{-1} 
    \begin{cases} \xv_n \ebx{k},& \text{if} j=k\\ 0,& \text{otherwise} \end{cases}\\
& = -\frac{\ebx{k}}{\sum_{m=1}^{K} \ebx{m}}
  \frac{\ebx{j}}{\sum_{m=1}^{K} \ebx{j}} \xv_n +
  \begin{cases} \frac{\ebx{j}}{\sum_{m=1}^{K} \ebx{j}} \xv_n,& \text{if} j=k\\ 0,& \text{otherwise} \end{cases}\\
%& = \frac{\ebx{k}}{\sum_{m=1}^{K} \ebx{m} } 
& = - g_k(\xv_n) g_j(\xv_n) \xv_n + \begin{cases} g_j(\xv_n) \xv_n,^ \text{if} j=k\\ 0,& \text{otherwise} \end{cases}\\
& = g_k(\xv_n) (\delta_{jk} - g_j(\xv_n)) \xv_n
    \end{align*}
$$
where $\delta_{jk} = 1$ if $j=k$, 0 otherwise.</p>
<p>Substituting this back into the log likelihood expression, we get</p>
$$
    \begin{align*}
      \grad_{\wv_j} LL(\wv) & = \sum_{n=1}^N \sum_{k=1}^K \frac{t_{n,k}}{g_k(\xv_n)} \grad_{\wv_j} g_k(\xv_n)\\
    & = \sum_{n=1}^N \sum_{k=1}^K \frac{t_{n,k}}{g_k(\xv_n)} \left (g_k(\xv_n) (\delta_{jk} - g_j(\xv_n)) \xv_n \right )\\
    & = \sum_{n=1}^N \left ( \sum_{k=1}^K t_{n,k} \delta_{jk} -
  g_j(\xv_n) \sum_{k=1}^K t_{n,k} \right ) \xv_n\\
& = \sum_{n=1}^N  (t_{n,j} - g_j(\xv_n)) \xv_n
    \end{align*}
$$<p>which results in this update rule for $\wv_j$</p>
$$
    \begin{align*}
        \wv_j  \leftarrow \wv_j + \alpha \sum_{n=1}^N
        (t_{n,j} - g_j(\xv_n)) \xv_n
        \end{align*}
$$<p>How do we do this in python?  First, a summary of the derivation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Derivation-Summary">Derivation Summary<a class="anchor-link" href="#Derivation-Summary">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$P(C=k\,|\,\xv_n)$ and the data likelihood we want to maximize:</p>
$$
    \begin{align*}
      g_k(\xv_n) & = P(C=k\,|\,\xv_n) =
      \frac{f(\xv_n;\wv_k)}{\sum_{m=1}^{K} f(\xv_n;\wv_m)}\\
      f(\xv_n;\wv_k) & = \left \{ \begin{array}{ll} \ebx{k}; & k < K\\ 1;& k = K \end{array} \right .\\
      L(\wv) & = \prod_{n=1}^N \prod_{k=1}^K p(C=k\,|\, \xv_n) ^{t_{n,k}}\\
      & = \prod_{n=1}^N \prod_{k=1}^K g_k(\xv_n)^{t_{n,k}}
    \end{align*}
$$<p>Gradient of log likelihood with respect to $\wv_j$:</p>
$$         
    \begin{align*}
      \grad_{\wv_j} LL(\wv) & = \sum_{n=1}^N \sum_{k=1}^K
      \frac{t_{n,k}}{g_k(\xv_n)} \grad_{\wv_j}
      g_k(\xv_n)\\
%& = \sum_{n=1}^N \left ( \sum_{k=1}^K t_{n,k} \delta_{jk} -
%  g_j(\xv_n) \sum_{k=1}^K t_{n,k} \right )\\
& = \sum_{n=1}^N \xv_n (t_{n,j} - g_j(\xv_n))
\end{align*}
$$<p>which results in this update rule for $\wv_j$</p>
$$
    \begin{align*}
        \wv_j  \leftarrow \wv_j + \alpha \sum_{n=1}^N
        (t_{n,j} - g_j(\xv_n)) \xv_n
        \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementation-in-Python">Implementation in Python<a class="anchor-link" href="#Implementation-in-Python">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Update rule for $\wv_j$</p>
$$
    \begin{align*}
      \wv_j  \leftarrow \wv_j + \alpha \sum_{n=1}^N
      (t_{n,j} - g_j(\xv_n)) \xv_n
    \end{align*}
$$<p>What are shapes of each piece?  Remember that whenever we are dealing with weighted sums of inputs, as we are here, add the constant 1 to the front of each sample.</p>
<ul>
<li>$\xv_n$ is $(D+1) \times 1$ ($+1$ for the constant 1 input)</li>
<li>$\wv_j$ is  $(D+1) \times 1$ </li>
<li>$t_{n,j} - g_j(\xv_n)$ is   a scalar</li>
</ul>
<p>So, this all works. But, notice the sum is over $n$, and each
term in the product as $n$ components, so we can do this as a dot product.</p>
<p>Let's remove the sum and replace subscript $n$ with
*.</p>
$$
    \begin{align*}
      \wv_j  &\leftarrow \wv_j + \alpha \sum_{n=1}^N
      (t_{n,j} - g_j(\xv_n)) \xv_n\\
      \wv_j  &\leftarrow \wv_j + \alpha (t_{*,j} - g_j(\xv_*)) \xv_*\\
    \end{align*}
$$<p>What are shapes of each piece?</p>
<ul>
<li>$(t_{*,j} - g_j(\xv_*))$ is $N \times 1$</li>
<li>$\xv_* = X$ is  $N \times (D+1)$</li>
<li>$\wv_j$ is  $(D+1) \times 1$ </li>
</ul>
<p>So, this will work if we transpose $X$ and premultiply it and define
$g$ as a function that accepts $\Xv$.</p>
$$
    \begin{align*}
%      \wv_j  &\leftarrow \wv_j + \alpha (t_{*,j} -
%      g(\xv_*;\wv_j)) \xv_*\\
      \wv_j  &\leftarrow \wv_j + \alpha \Xv^T (t_{*,j} -
      g_j(\Xv))
    \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's keep going...and try to make this expression work for
all of the $\wv$'s.
Playing with the subscripts again, replace $j$ with *.</p>
$$
    \begin{align*}
      \wv_j  &\leftarrow \wv_j + \alpha \Xv^T (t_{*,j} - g_j(\Xv))\\
      \wv_*  &\leftarrow \wv_* + \alpha \Xv^T (t_{*,*} - g_*(\Xv))
    \end{align*}
$$<p>Now what are shapes?</p>
<ul>
<li>$\wv_* = \wv$ is  $(D+1) \times K$</li>
<li>$t_{*,*} = T$ is  $N \times K$</li>
<li>$g_*(\Xv)$ is   $N \times (K-1)$</li>
<li>$t_{*,*} - g_*(\Xv)$ is  $N \times K$</li>
<li>So, $\Xv^T (t_{*,*} - g_*(\Xv))$ is  $(D+1) \times K$</li>
<li>So, $\Xv^T (T - g(\Xv))$ is  $(D+1) \times K$</li>
</ul>
<p>Now our update equation for all $\wv$'s is</p>
$$
    \begin{align*}
      \wv  &\leftarrow \wv + \alpha \Xv^T (T - g(\Xv))
    \end{align*}
$$<p>We had defined, for $k = 1,\ldots, K$,</p>
$$
    \begin{align*}
      f(\xv_n;\wv_k) & =  \ebx{k} \\
        g_k(\xv) &=  \dfrac{f(\xv;\wv_k)}{\sum_{m=1}^K f(\xv;\wv_m)}
      \end{align*}
$$<p>Changing these to handle all samples $\Xv$ and all parameters
$\wv$ we have</p>
$$
    \begin{align*}
      f(\Xv;\wv) & = e^{\Xv \wv}\\
      g(\Xv) & = \frac{f(\Xv;\wv)}{\text{rowSums}(f(\Xv;\wv)}
    \end{align*}
$$<p>Given training data $\Xv$ ($N\times (D+1)$) and class
indicator variables $T$ ($N \times K)$), these expressions
can be performed with the following code.</p>
<p>First, we need a function to create indicator variables from the class labels, to get</p>
$$
\begin{bmatrix}
1\\
2\\
2\\
1\\
3
\end{bmatrix}
\Rightarrow
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 1
\end{bmatrix}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">makeIndicatorVars</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="c1"># Make sure T is two-dimensiona. Should be nSamples x 1.</span>
    <span class="k">if</span> <span class="n">T</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">T</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">T</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([[1],
       [2],
       [2],
       [1],
       [3]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">makeIndicatorVars</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([[1, 0, 0],
       [0, 1, 0],
       [0, 1, 0],
       [1, 0, 0],
       [0, 0, 1]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># import pdb</span>
<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
    <span class="n">fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>  <span class="c1"># N x K</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fs</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># pdb.set_trace()</span>
    <span class="n">gs</span> <span class="o">=</span> <span class="n">fs</span> <span class="o">/</span> <span class="n">denom</span>
    <span class="c1"># print(gs[:10,:])</span>
    <span class="k">return</span> <span class="n">gs</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The function <code>g</code> is sometimes called the <em>softmax</em> function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the updates to $\wv$ can be formed with code like</p>

<pre><code>TI = makeIndicatorVars(T)   
w = np.zeros((X.shape[1],TI.shape[1]))
alpha = 0.0001
for step in range(1000):
    gs = g(X,w)
    # Error does not involve the last column of indicator variables in TI nor gs
    w = w + alpha * np.dot(X.T, TI - gs) 

</code></pre>
<p>Here is code for applying linear logistic regression to the Parkinsons data from last lecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loadParkinsonsData</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">header</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="n">names</span> <span class="o">=</span> <span class="n">header</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">f</span> <span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">))</span>

    <span class="n">targetColumn</span> <span class="o">=</span> <span class="n">names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">XColumns</span><span class="p">,</span> <span class="n">targetColumn</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="n">XColumns</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="n">targetColumn</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># to keep 2-d matrix form</span>
    <span class="n">names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">names</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">names</span> <span class="o">=</span> <span class="n">loadParkinsonsData</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">names</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[9]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>((195, 22),
 (195, 1),
 [&#39;MDVP:Fo(Hz)&#39;,
  &#39;MDVP:Fhi(Hz)&#39;,
  &#39;MDVP:Flo(Hz)&#39;,
  &#39;MDVP:Jitter(%)&#39;,
  &#39;MDVP:Jitter(Abs)&#39;,
  &#39;MDVP:RAP&#39;,
  &#39;MDVP:PPQ&#39;,
  &#39;Jitter:DDP&#39;,
  &#39;MDVP:Shimmer&#39;,
  &#39;MDVP:Shimmer(dB)&#39;,
  &#39;Shimmer:APQ3&#39;,
  &#39;Shimmer:APQ5&#39;,
  &#39;MDVP:APQ&#39;,
  &#39;Shimmer:DDA&#39;,
  &#39;NHR&#39;,
  &#39;HNR&#39;,
  &#39;RPDE&#39;,
  &#39;DFA&#39;,
  &#39;spread1&#39;,
  &#39;spread2&#39;,
  &#39;D2&#39;,
  &#39;PPE&#39;])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">standardize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">stds</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="n">stds</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">runParkLogReg</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainFraction</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">header</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="n">names</span> <span class="o">=</span> <span class="n">header</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">f</span> <span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">))</span>

    <span class="n">targetColumn</span> <span class="o">=</span> <span class="n">names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">XColumns</span><span class="p">,</span> <span class="n">targetColumn</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">XColumns</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">targetColumn</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># to keep 2-d matrix form</span>
    <span class="n">names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>

    <span class="n">healthyI</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">parkI</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">healthyI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">healthyI</span><span class="p">)</span>
    <span class="n">parkI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">parkI</span><span class="p">)</span>

    <span class="n">nHealthy</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">trainFraction</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">healthyI</span><span class="p">))</span>
    <span class="n">nPark</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">trainFraction</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">parkI</span><span class="p">))</span>
    <span class="n">rowsTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">healthyI</span><span class="p">[:</span><span class="n">nHealthy</span><span class="p">],</span> <span class="n">parkI</span><span class="p">[:</span><span class="n">nPark</span><span class="p">]))</span>
    <span class="n">Xtrain</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">rowsTrain</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">Ttrain</span> <span class="o">=</span> <span class="n">T</span><span class="p">[</span><span class="n">rowsTrain</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">rowsTest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">healthyI</span><span class="p">[</span><span class="n">nHealthy</span><span class="p">:],</span> <span class="n">parkI</span><span class="p">[</span><span class="n">nPark</span><span class="p">:]))</span>
    <span class="n">Xtest</span> <span class="o">=</span>  <span class="n">X</span><span class="p">[</span><span class="n">rowsTest</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">Ttest</span> <span class="o">=</span>  <span class="n">T</span><span class="p">[</span><span class="n">rowsTest</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">means</span><span class="p">,</span><span class="n">stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Xtrain</span> <span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Xtrains</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">)</span>
    <span class="n">Xtests</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">)</span>
    
    <span class="n">Xtrains1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xtrains</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrains</span><span class="p">))</span>
    <span class="n">Xtests1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xtests</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Xtests</span><span class="p">))</span>

    <span class="c1"># New stuff for linear logistic regression</span>

    <span class="n">TtrainI</span> <span class="o">=</span> <span class="n">makeIndicatorVars</span><span class="p">(</span><span class="n">Ttrain</span><span class="p">)</span>
    <span class="n">TtestI</span> <span class="o">=</span> <span class="n">makeIndicatorVars</span><span class="p">(</span><span class="n">Ttest</span><span class="p">)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrains1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">TtrainI</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">gs</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtrains1</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xtrains1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">TtrainI</span> <span class="o">-</span> <span class="n">gs</span><span class="p">)</span>
        <span class="n">likelihoodPerSample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">TtrainI</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gs</span><span class="p">))</span> <span class="o">/</span> <span class="n">Xtrains</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">likelihoodPerSample</span><span class="p">)</span>
        <span class="c1"># print(&quot;Step&quot;,step,&quot; l =&quot;,likelihoodPerSample)</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>

    <span class="n">logregOutput</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtrains1</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">predictedTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logregOutput</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">logregOutput</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtests1</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">predictedTestLR</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logregOutput</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LogReg: Percent correct: Train </span><span class="si">{:.3g}</span><span class="s2"> Test </span><span class="si">{:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTrain</span><span class="p">,</span> <span class="n">Ttrain</span><span class="p">),</span>
                                                                     <span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTestLR</span><span class="p">,</span> <span class="n">Ttest</span><span class="p">)))</span>

    <span class="c1"># Previous QDA code</span>
    
    <span class="n">Ttr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ttrain</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,</span> <span class="p">:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cov1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">Ttr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ttrain</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">mu2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,</span> <span class="p">:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cov2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="n">d1</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">nHealthy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">nPark</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">predictedTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">d1</span><span class="p">,</span><span class="n">d2</span><span class="p">)),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">d1t</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">nHealthy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">d2t</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">nPark</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">predictedTestQDA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">d1t</span><span class="p">,</span> <span class="n">d2t</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   QDA: Percent correct: Train </span><span class="si">{:.3g}</span><span class="s2"> Test </span><span class="si">{:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTrain</span><span class="p">,</span> <span class="n">Ttrain</span><span class="p">),</span>
                                                                     <span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTestQDA</span><span class="p">,</span> <span class="n">Ttest</span><span class="p">)))</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">colspan</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Ttest</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictedTestLR</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictedTestQDA</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">percentCorrect</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">==</span><span class="n">t</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">discQDA</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">prior</span><span class="p">):</span>
    <span class="n">Xc</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu</span>
    <span class="k">if</span> <span class="n">Sigma</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">det</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>        
    <span class="k">if</span> <span class="n">det</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">(</span><span class="s1">&#39;discQDA(): Singular covariance matrix&#39;</span><span class="p">)</span>
    <span class="n">SigmaInv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>     <span class="c1"># pinv in case Sigma is singular</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">det</span><span class="p">)</span> \
           <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xc</span><span class="p">,</span> <span class="n">SigmaInv</span><span class="p">)</span> <span class="o">*</span> <span class="n">Xc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> \
           <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">runParkLogReg</span><span class="p">(</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>LogReg: Percent correct: Train 85.9 Test 84.6
   QDA: Percent correct: Train 99.4 Test 89.7
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">runParkLogReg</span><span class="p">(</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>LogReg: Percent correct: Train 91 Test 76.9
   QDA: Percent correct: Train 100 Test 87.2
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">runParkLogReg</span><span class="p">(</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>LogReg: Percent correct: Train 85.3 Test 92.3
   QDA: Percent correct: Train 99.4 Test 92.3
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJztnXuUXHWV7z+7uvqVB3mQDoHuhBA7BBIUhARQ0UEZCbZO
GL3CzTzAITiZxDjDqGt8LEcvPtYyd7jjvbCiZDKOgzpjcn1hUCARvSqOIiEBhKQRExJCuklIk5B3
1+ucff+oU9XV9eg+J93pqjpnf9bq1V2/Oqf6d06f+va39m+fvUVVMQzDMKJDrNoTMAzDMMYWE37D
MIyIYcJvGIYRMUz4DcMwIoYJv2EYRsQw4TcMw4gYJvyGYRgRw4TfMAwjYpjwG4ZhRIx4tSdQjmnT
puns2bOrPY2aZdu2ba+qatvp7Gvn1jDCSRBdqEnhnz17Nlu3bq32NGoWEdl7uvvauTWMcBJEFyzU
YxiGETFM+A3DMCKGCb9hGEbEMOE3DMOIGCb8hmEYEcOE3zAMI2KY8BuGYUSMmszjN7JkHJfnXznO
Uy8dQYFbrj6/2lMyDCMEmPDXEEdPpXl8zyGefOkIT730Gs/0HKU/7QDwho5JJvyGYYwKJvxV5Hgi
zRMvHuY3uw7x2O5DdO8/hio0Ngjzz5vEf180kzfOmszls6bQMaW12tM1DCMkmPCPIarKC30n+dlz
r/Cz3x9k297XcFylqSHGG2dN5o7r5vKmOWdz6czJtDQ2VHu6hmGEFBP+M4yq8tS+Izz4zH5++twr
7D10CoCLZkzkb942h2s6p3H5+VNM6A3DGDNM+M8Qf3jlOBuf7uVHv9vPS4dP0dQQ482dZ/PBt87h
HRdNp32yhW4Mw6gOJvyjSH/K4UfPvMx/Pv4Sv9t3hJjAWzqn8bfv6GTxJTM4q6XR92stW7aMH//4
x0yfPp3t27eXPC8iAtwNdAGngL9S1SdH61jqgQd3P8jdT97NgZMHmDF+BndcfgfvnvNuHvzFZ7h7
9/0ciMEMF+6Y816AkrF3X/sF7vnuR9l4dDN9caEto9w4aTF/d9OXIzUO1Mxcqjn+uf/3Lb6/519x
G14j5kzhv13w1/yPd9xSU+dstBBVHbUXGy0WLlyo9VQ6eN/hU/zbf+3h+0/2cDyRoXP6BP78yln8
yaXn0Tax+bRe89FHH2XChAnceuutJcIvItuAzwJ/S1b4rwLuVtWrhnvdeju3lXhw94Pc+Zs7STiJ
/FhLQws3Tl7Axr6tJGKSH4+7LiJCWgbGWlzlWmbwC/aTiMUKxl2uSk/n8caDkRiPuy6CkI7JqL92
PY0v4GK2shuJpfPj6jaykDns4LmaOGe3TBha/EVkm6ourLhB4bYm/KfP7w8c495fvMCPn9lPTOBd
l5zLX1w1iysvmIoUiMzp8uKLL/Ke97ynkvBvA36hquu9seeBa1V1/1CvWS/ndjiu/9717D9Zeqgx
VVyf577StlEbL0etzfFMj4sqGmC8HGd6jtPTLj/74I6Kvz+I8Fuo5zR4oe8E/7Tp92ze8QrjmhpY
9pbZ3H7NHGZMahnLabQD+woe93hjJWooIsuB5QCzZs0ak8mdaQ6cPFB23K+wDbVt1MZraS7VGq8k
7n5FfzTnUmm8Lz5yM5nDhD8AB48nuPunO9nwxD5a4jHuuG4ut71lNpPHNVV7akOiquuAdZB1/FWe
zqgwY/wMc/zm+CPl+Nsyo/fWtVo9PnBd5Vu/3ct1/+uX/N8n9vGXV83ilx9/Ox9554XVFP1eYGbB
4w5vLBLccfkdNMUGn/uWhhZumraQFtcdNB53XRqLQpotrnK9zijZtsV1eWuqLTLjcdel0S0+N7U1
x7EYv1wvQt3ByRfqNnK5XlQz5yy3qDwamPAPw85XjvP+tb/hMz/czus7JvGTj7yNz914CdMmnN6i
7SjyAHCrZLkaODpcfD9MvHvOu/nAgg/kH587/lzufPOd/ON77uPOSZdxbjqDqHKuo3zxgvfxhdnv
5VxH82N3XvBe7rrtp9wyYTHT0y6iyvR0dgFtzfKfR2b8tgmL+asJ19fEXMZyPHd95Mbvu+173HT+
R5DMFFRBMlO46fyPcN9t32NF7OJB21frnI1mVg+qWnNfV1xxhVYb13X1W4+9qBd++iG97HOb9Xtb
96nrumP2+5cuXaozZszQeDyu7e3t+rWvfU3vvfdevffeexXYCgjwFeAF4FlgodbJuR0tftXzK73k
vkv06YNPD37i6Q2q/+Ms1Vd3+Xqdf9r0nL7uUw+egRkaNcuXZqo+9HF/2wa8nqoFsFV9aqzF+Mtw
LJHm4999hk07DvC2C9v455suPe20zNNl/fr1FZ9buXIl3h961djNqPZIOkkAmhuK/jaZ/uz3uL/F
9kTapTluH34jRbwF0v3+ts14KcPxqn/KHzVM+It48dWT3P6NJ9h76BSf7rqY26+5gFhs9FbTjdEj
5aQAaGooWmfJZP8h+BX+ZMah2UpmRIt488B1MhwBr6d6wIS/gMd3H+Jv/mMbAN+6/Sre9Lqzqzwj
YygSnhNraSh6Q+acXKN/x99ijj9axFsHPhkOR8BPkPWACb/Hz58/yIpvbaN9Sitf/8AiZk8bX+0p
GcMweo7fNccfNczxG5t3HODD336SC8+ZyLduv4qp42s7L9/IUjnGn4BYI8T8iXky7ViMP2rEWwZi
98ORSUAsDg3hkcvwHMlp8ugf+lj1n09ySfskvrHsSia1+i+kZlSXnPCXhHoyiUDuLGGOP3o0tkDa
p/Cng11P9UCkbc4zPUdY8R/bmHvORL55u4l+vZF0kghCPFbkXzKJQBkY5vgjSFDHH6KMHoiw8Pce
6WfZfU8wZVwT37htUaCSyUZtkHJStMRbSgviZZLQ6L/fQTLjWiOcqBFvCRbjj4erf0YkhT+RdvjQ
f2wjkXb5xrIrmX5WuD7GRYWEkyhd2IVsVk8Ah5Ywxx894i3BsnpC5vgjGeP/3I+6+V3PUdb+5RV0
Tp9Q7ekYp0nKSdEcK/OGzCQDxWRTGbuBK3IEzeqJYoxfRG4QkedFZJeIfLLM8/8gIk97X9tFxBGR
qX72HWs2bd/P+i0vseKPXscNl8yo9nSMEZBwEjSXc2IBF3ct1BNBGlv9x/jT/b7vCakXhhV+EWkg
WxPmXcB84M9EZH7hNqp6l6pepqqXAZ8Cfqmqh/3sO5YcOpHk0/dv55L2s/jY9RdWaxrGKJFyUqWp
nBA8q8dCPdEj3uw/qyeijv9KYJeq7lbVFLABuHGI7f8MyBWaCbrvGeUzG7dzPJHhn2+6jMYGe6PX
O0knWT7GHzSrJ+PSHDfHHylyWT3qo8Z9RLN6KnV6KkFExgE3AN8/jX2Xi8hWEdna19fnY1rB+OUf
+njo2QPc8cdzmTdj4qi/vjH2JDPJ0hx+yDq5AFk9ibRDS6MZgUgRbwEUvLu/hySTsKyeYfgT4Neq
ejjojqq6TlUXqurCtra2UZ1UKuPyuR/tYPbZ4/jgWy8Y1dc2qsdoOP6M45Jx1Rx/1MiFbvzE+SPq
+IN0elrKQJgn6L5njG8+9iK7+07ymffMtzd4iEg6yQoxfv951ykn2+nIHH/EyAm5n8yegPeF1AN+
rvYngLkicoGINJEV9weKNxKRScAfARuD7nsmOZHMsObnu3jr3Gm846LpY/mrjTNMZeH3n3edSGeF
3xZ3I0ZOyP3U5A94X0g9MGwev6pmROTDwGagAfi6qu4QkRXe82u9Td8L/ERVTw6372gfxFB84zcv
cuRUmo9dP6/0Dk+jrhna8fuvxQ9YrZ6okQ/1+HT8Icvq8XUDl6o+BDxUNLa26PF9wH1+9h0rjifS
rHt0N++4aDqXzZxcjSkYZ5CUk6qcx+8z7zqZtlBPJAkc4w+X8If6av/24y9xtD/N3//x3GpPxTgD
JJxEqeN3MuBm/LddzDl+W/uJFn6F33XATZvw1wsZx+Wbj+3l6jlTeUOHuf0wknJSZZqwBOuPmrQY
fzTJL+4OI/wh7LcLIRb+R7pfofdIP7e9xdI3w4iqknTK5PHnuyX5y8JIZnKhHnP8kSK3uDtcjD93
d28Es3rqkn//zYt0TGnljy8+p9pTMc4AKbdS28Vcf1S/WT25UE9o3wpGOXLXx3BZPeb464cX+k6w
Zc9h/vLq82mIWSZPGKncdjF4v12wGH/k8JvVkxd+i/HXPD94soeYwPveWLY6hBECkpkKwp9zcD6z
enKO37J6IobfxV0T/vrAdZX7n+zlbRe2WYOVEGOO3xgRJvzh4rHdh3j5aIL3Xd5R7akYZ5CUV1yr
VPiDvVFzN3CZ448YvrN6PCMRtXr89caPn3mZ8U0NXD/fFnXDTMLJvmFLhT+3uOs31GOOP5LkSzYM
I/zpYNdTvRAq4Xdc5ZHuV7j2oumhSM/btGkT8+bNo7Ozk9WrV5c8LyKTRORHIvI7EdkhIrdVYZpV
obLjz4V6fObx50s2hOqtYAxHLA4S8+/4Laundnnqpdd49USKxQvqv6Wi4zisWrWKhx9+mO7ubtav
X093d3fxZquAblW9FLgW+GevGF7oyTn+ijdw+cy7thu4IorIQDOWociHDi2Pv2bZvOMAjQ3C2+eN
bj3/arBlyxY6OzuZM2cOTU1NLF26lI0bNxZvpsBEyVafmwAcBjJjPddqkHP8LcUfwdPB8q4TGYem
eMwK+EWRQMJvjr9m+Un3K7z5ddOY2NJY7amMmN7eXmbOHGhl0NHRQW9vSSuDNcDFwMvAs8AdquqO
2SSrSC6rp3LJBv9F2sztR5RAwm8x/ppk76GT7D10Kmo19xcDTwPnAZcBa0TkrOKNznRby2qQ8N6Q
lUs2+E/nDMN6kHEaNLYEKNlgwl+T/NeuVwG4Zu60Ks9kdGhvb2ffvoF2xT09PbS3l9yQdhvwA82y
C9gDXFS80Zlsa1ktcqGeyiUb/Dp+xxx/VIm3BCjZYMJfk/x616ucN6mFOdPGV3sqo8KiRYvYuXMn
e/bsIZVKsWHDBpYsWVK82UvAdQAicg4wD9g9xlOtCsPfwOU3q8ccf2SJN/so2RDsE2S94KsRS63j
uMqvdx3i+vnnhGaRLh6Ps2bNGhYvXozjOCxbtowFCxawdu1agJxt/wJwn4g8CwjwCVV9tVpzHksq
C7/XNMPndZDMmOOPLPFWHzH+fmho9n091QuhEP4dLx/laH86NGGeHF1dXXR1dQ0aW7FiBStXruwD
UNWXgeurMbdqU3FxN50IlIGRsMXd6BJvhtSJobcJYdtFCEmoZ8uewwC8ac7ZVZ6JMVaknBRxiROP
FXmXTCJQznUy41ioJ6r4zeoJ2cIuhET4t+19jZlTW60oW4RIOInK/XbN8Rt+aGzxUbIh2PVUL9T9
Fa+qbNv7GlfMmlLtqRhjSMpJlcb3IXBj7GyM3xx/JIn7SOcMYaN1CIHw9x7p5+DxJJefb8IfJRKZ
RGl8H7Jv5AAfzbNZPXX/NjBOh3izv1CPCX/tsW3vawBcbo4/UqScVOnNW5DNyw7wRk2kzfFHFl9Z
PSb8NcmTe19jXFMDF82YWO2pGGNI0klWdvwBYrLJjGuVOaOKL8cf7HqqF+r+in+29yiXnDeJeEPd
H4oRgKSTLO/4g2b1pO0GrsjS2ApOCtwhylul+31Xeq0n6lotHVf5/YHjzD+vpDyNEXIqO37/WRiq
SsJu4IoufrpwmeOvPfYeOsmplMMCE/7IMWRWj0+HlnYUVczxRxU/fXcDfoKsF+pa+Lv3HwMwxx9B
Ek6igvD7d2j57lvm+KNJXviHSOkMeF9IvVDXV3z3y8dobBDmTreF3ahR0fEHyOpJWPetaJMX/iEq
dFpWT+2x4+VjdE6fSJO9cSPH0Fk9fmvx5/rtWqgnkuRj/EM5/mD3hdQLda2Y3fuPMf9cC/NEkaST
LG27qJp1b+b4DT/k1oIqxfhVA98XUi/U7RX/2skUfceTlr8fUco6fq85S/AYvzn+SJK7TirV63HS
gFqMv5bY/Wq2nOrrpoej8YoRjGQmWb4WP/jO6klmso7fSjZElOGyevLd3Cyrp2Z44eBJAF7XNqHK
MzHGmoybIaOZUuHPOTefDi2RNscfaYYV/mDd3OoJX8IvIjeIyPMisktEPllhm2tF5GkR2SEivywY
f1FEnvWe2zpaE3/h1RM0NcTomDJutF7SqBNy/XYrOv4AjdYBK9kQVYYV/nD22wUfHbhEpAH4CvBO
oAd4QkQeUNXugm0mA18FblDVl0RketHLvH20WwK+cPAkF0wbT0MsXC3RjOEZvt+u30brXqjHHH80
aRwmjz8dLHRYT/ixOlcCu1R1t6qmgA3AjUXb/DnwA1V9CUBVD47uNEvZ3XfC4vsRpbLw52KyQdM5
zfFHktx1kq6Qx58JFjqsJ/xc8e3AvoLHPd5YIRcCU0TkFyKyTURuLXhOgZ9648sr/RIRWS4iW0Vk
a19f35ATSmVc9h4+xZxpFt+PIrlQT0lWT865+cy7zjt+y+OPJsPduZv/BBk+xz9azdbjwBXAdUAr
8JiI/FZV/wBco6q9XvjnERH5vao+WvwCqroOWAewcOFCHeqXvXT4JI6r5vgjSsLJOrGSPP7AMX4r
2RBpfGf1RNPx9wIzCx53eGOF9ACbVfWkF8t/FLgUQFV7ve8HgfvJho5GxIuvngJg9tkm/FGk4uJu
Opjw2w1cEWe46pwB14zqCT9X/BPAXBG5QESagKXAA0XbbASuEZG4iIwDrgKeE5HxIjIRQETGA9cD
20c66X2vZYV/1lTL6IkiCe+NWhrqOT3Hb6GeiBJrgFjj8Fk9ISzZMGyoR1UzIvJhYDPQAHxdVXeI
yArv+bWq+pyIbAKeAVzga6q6XUTmAPeLSO53fVtVN4100vsO99Pa2MDU8WVqtRihJ+f4SxqxBBT+
RNolJhC3zLDo0tg6fFZPCB2/rxi/qj4EPFQ0trbo8V3AXUVju/FCPqPJvtdOMXNqK94/FCNi5LJ6
Kjt+/yUbmuMNdh1FmXizZfXUC/sOn2Km3bgVWYbN4w9QssHKNUSceMsQWT054Q9fVk/dXfWqSu9r
/cy0+H5kqSj86WBZGIm0Y+Uaok68pXI9fnP8tcPR/jTHkxk6poTvv3AxmzZtYt68eXR2drJ69eqy
21QqlRFmhr9z1xy/4RM/jj+Ed+6OVh7/mLHvcPa/c9gdv+M4rFq1ikceeYSOjg4WLVrEkiVLmD9/
fn4bH6UyQkle+IudWCYB0gAN/i7rZNo1xx91GlsqZ/WkEyAxiNWdTA5L3dmdXCpn2B3/li1b6Ozs
ZM6cOTQ1NbF06VI2btxYvNmYl8qoBSo7/mBt8hIZx8o1RJ14S+V6/LnrKYSL/3V31fe+lnX8Ya/K
2dvby8yZA/fNdXR00NtbfN/ckKUyQku+ZEOsTFZPgJzrZNq1Am1RJ9489A1cIUzlhDoM9ew/mmBc
UwNntdTd1M8EQ5XKyOPVSFoOMGvWrDGf5GiTcBI0NzSXpmEGdPzJjMP4ZruOIs2QMf5wtl2EOnT8
rxxPMOOsltDnXre3t7Nv30BtvJ6eHtrbi2vjVS6VUYiqrlPVhaq6sK2t7UxOe0xIOanyjdbTiUAZ
GIm0a+Uaos6QWT3JUGb0QD0K/9EE55wVzv/ChSxatIidO3eyZ88eUqkUGzZsYMmSJcWblS2VMeaT
HWMSmURpfB88x+9/7SeZcWi2cg3RZijHn+4PZUYP1GGo58CxBItmT632NM448XicNWvWsHjxYhzH
YdmyZSxYsIC1a9cCtAFUKpVRxWmPCSknNYTwm+M3AjBUVk+IHX9dCb+qcvBYkulnhfOPUUxXVxdd
XV2DxlasWMHKlSvzDQvKlcoIO0mnTKN1CLwYl8xYOmfk8ZPVE0Lqyu4cPpki5bjMiECox6hMZeEP
mNWTcewGrqgzZFaPCX9NcOBY9g9kwh9tKgp/OmBWj93AZcRbQR1wMqXPmfDXBgePZRdhzpkUzj+G
4Y+hY/z+rg3XVVKOlWyIPPlmLGUyezLJUNbihzoTfnP8BmTz+MumcwaI8aecXPctc/yRZqi+uwE/
QdYT9SX8RxOIQNvEaCzuGuVJOanSfrvg3XDjvzInWNvFyJNz9OVq8gfMEqsn6uqqP3g8ydRxTTQ2
1NW0jVEm6SQrO/4AtfjB2i5GnqEcfyYZylr8UGfCf/hkkmkTwvkf2PBPMpMsbbsIgRxa0hqtG1Ag
/GUyewJ8gqw36uqqP3QixdkTrM9u1Em6ZRy/64CT8t9v12u0btU5I04l4XfdQNdTvVFXV/2hkynO
NscfeZKZMumc+SYs/t6oOcdv1TkjTj6rp0j4801YTPirzqsnkpw93hx/lFHV8nn8+TZ5PoXfHL8B
A2tClYTfHH91SWYcjicyJvwRJ+NmUHQI4feb1WPpnAYD10tx2Yb8J8hwRhjqRvgPn8w237BQT7RJ
ONk3aEmMP2B/1Jzjtxu4Ik6lGH/uhi7L6qkuh07khN8cf5TJtV0syepJm+M3ToNK6Zzm+GuDQ57j
n2bCH2nybRcrOX6fDs0cvwEUCH/RDVwBP0HWG3Vz1R86kf0PfPb4cP4HNvyRC/VUzurxmcefMcdv
UJDVU+T4A36CrDfqSPizTm+qOf5Ik3P8zcVvyHxM1mcev5VsMGDA0ReXbLCsntrg1ZNJmhpiTLTm
2JEmkRnG8fvMu7aSDQYADU2ADBHjN+GvKodPpJg6vin0TdaNock7/pHm8XuLu03m+KONiNd3t1JW
jwl/VTnSn2byuMZqT8OoMrmsnhLhD5rVk3FobBAaYmYkIk+5LlyW1VMbHD2VZlKrCX/UqSj8QbN6
0q6VazCylHP8uZi/ZfVUl6Pm+A2GEv6gWT2OlWswsjS2WIy/VjnSnzLHbwwR4w/m0BLWb9fIEW+x
rJ5aJev4LZUz6lQu2eA5tHK9eMtgjt/IE28u4/gtjx8RuUFEnheRXSLyyQrbXCsiT4vIDhH5ZZB9
hyORdkikXXP8Rt7xl7ReTPdnU/Ni/sTcHL+RJ95avjpnrBFi4bxGhk2KF5EG4CvAO4Ee4AkReUBV
uwu2mQx8FbhBVV8Skel+9/XDsf40AGeZ8EeeXIy/rOMPUFArmXGsXIORpVJWT0gXdsGf478S2KWq
u1U1BWwAbiza5s+BH6jqSwCqejDAvsNy1BP+ySb8kSeRSRCTGHEp8iwBG2MnM67dtWtkqZTVE9Iw
D/gT/nZgX8HjHm+skAuBKSLyCxHZJiK3BtgXABFZLiJbRWRrX1/foOeOeMJvoR4j5aRobmguvZEv
kwi0EJdMOxbqMbJUyuoJ6cIu+Aj1BHidK4DrgFbgMRH5bZAXUNV1wDqAhQsXauFzR095jt/SOSNP
wkmUZvRAVvgDtMlLZlwL9RhZymb19Ida+P1c+b3AzILHHd5YIT3AZlU9qaqvAo8Cl/rcd1iORtTx
b9q0iXnz5tHZ2cnq1asrbicii0QkIyLvH8PpVYWc4y8hkzyNUI85fgMv1BMtx+9H+J8A5orIBSLS
BCwFHijaZiNwjYjERWQccBXwnM99h+VIPsYfnXROx3FYtWoVDz/8MN3d3axfv57u7tI1cW8B/X8C
PxnzSVaBsv12wYvJ+n+jJtKOxfiNLPGW8vX4oxzjV9UM8GFgM1kx/46q7hCRFSKywtvmOWAT8Ayw
Bfiaqm6vtG/QSR7tTyMCE1uiU5lzy5YtdHZ2MmfOHJqamli6dCkbN24st+nfAt8HDpZ7MmwknWRp
Rg8EdmjZUI85foPyefzpRKizenwpqao+BDxUNLa26PFdwF1+9g3K0VMpJjbHiUWooFZvby8zZw5E
yTo6Onj88ccHbSMi7cB7gbcDiyq9logsB5YDzJo160xMd8xIOsnStouQdWjjzvb/Oub4jRyNXh6/
arZaJ3jX09TqzusMUhdX/vFExnL4y/N/gE+oqjvURqq6TlUXqurCtra2MZramSHlpCo4/mCLuwlz
/EaOcl24Qh7jr4vYyfFkhgkRa8DS3t7Ovn0DmbA9PT20t5dkwi4ENnipjdOALhHJqOoPx2yiY0zC
STA+Pr70iQDpnBnHxXHVHL+RJd93t8A8WFZP9TmRyEQqvg+waNEidu7cyZ49e0ilUmzYsIElS5YM
2kZVL1DV2ao6G/ge8KEwiz54WT3lFt3S/hfjErl+u5bOaUCB8JvjrylOpjJMHR+djB6AeDzOmjVr
WLx4MY7jsGzZMhYsWMDatWsB6jteMwISmSHy+H3X4s/227VQjwEUCH9BZk/A0GG9URfCfyKRYdbU
cdWexpjT1dVFV1fXoLEVK1awcuXKvuJtVfWvxmpe1WQ08vhz/XYt1GMA5WP86WB3gtcbdXHln4hg
jN8oT9k8ftVAMdmE5/jtBi4DGEjbLKzXE/U8/lrAhN/IUVb43Qyo6/ujec7xW8kGAxgQ+FzfZicN
6gSq9lpv1PyV77jKqZTDeBN+gwo3cAXsljQQ6jHHbzA4q6fwuzn+6nEylQGiddeuUR5XXdJuuvQG
rnQw4c+HeszxGzDg7PPC78X6Q3znbs1f+ScSWeG3UI9RuQmLOX5jBOQXd73rKFep0xx/9TiZzAq/
hXqMim0Xcw7Nr/DnF3dr/vI3xoL84m5y8HfL6qkexz3hn2ChnshT2fF7Ds3n4m4iv7hrjt+gYHHX
u44CfoKsR2pe+HOO30I9RtJzYiVZPeb4jZFQfOeuCX/1sRi/kSPn+EuFP1gWRtJKNhiFWFZP7XHC
HL/hUVH481k9/rIwElaywSikkvBbVk/1yIV6xjXZmzTqDJ/VYyUbjNOgIQ7SUJDVY46/6vSns2/S
cU3m+KNOTvhL8viDpnOmHUSgqaHmL39jrGhstRh/LZGwhTjDY9gYf4CSDc3xGCLR6ehmDEO82bJ6
aolE2qGlMRaptotGeUbzBi67ecsYRLzFHH8t0Z92aLVFOIOCG7hGoWSDFWgzBhFvKVOywYS/avSn
TPiNLAkn+8Y0x2+MOoXCny/ZYMJfNfrTjqXdGcBwJRsEGhp9vU4y49iakTGYxmLHL1BsMEJEzV/9
CRN+w2PIkg2NreBzsTaRdu2aMgYTbxkIGWa87lshXvyvA+F3abUcfoNhSjYEyLk2x2+UEG8efANX
iHP4oQ7NMOCdAAAPmUlEQVSE3xZ3jRxJJ0ljrJGYFF22OYfm93XSrpVrMAYTL8rjD3F8H+pB+FMW
6jGylG27CIEbYycyDi22uGsUEm8eqPKaSYY6owfqQPgTacdCPQZQoe0imOM3Rk5hHn+63xx/tcmG
emp+msYYkHSSpTn8EDgmm8g4ls5pDKY4q8di/NXFYvxGjiEdf4BKism0azdwGYMZlNXT77vSa71S
81d/Iu3QYqEegyFi/IGzeuwGLqOIQVk95viriqpmc67tTWqQvYGrudwbMh3MoSXSjsX4jcHEW8FN
g+sE/gRZj9T01Z9yrFOSMUAikxix41dVc/xGKbnrJ5PwssTM8VeNlNcwI6p10zdt2sS8efPo7Oxk
9erVJc+LyF+IyDMi8qyI/EZELq3CNMeMlJOqIPz+s3ryZsJu4DIKyTn8TNLy+HOIyA0i8ryI7BKR
T5Z5/loROSoiT3tfny147kVPmJ4Wka1BJpd2FIDGCAq/4zisWrWKhx9+mO7ubtavX093d3fxZnuA
P1LV1wNfANaN+UTHkIRTyfEnfOddJ7zGPnZviDGInMNP93ufIMMt/MO2tRKRBuArwDuBHuAJEXlA
VYtV6Feq+p4KL/N2VX016OTSnjuLovBv2bKFzs5O5syZA8DSpUvZuHEj8+fPz2+jqr8p2OW3QMfY
znJsSTmpEefxJzPW2McoQ2Hf3Yzl8QNcCexS1d2qmgI2ADee2WllyYd6Ivgm7e3tZebMmfnHHR0d
9Pb2DrXL7cDD5Z4QkeUislVEtvb19Y3uRMeQynn8/mP8ybSFeowy5IU/aVk9Hu3AvoLHPd5YMW/2
4s0Pi8iCgnEFfioi20RkeZDJpfKOP7xV8kYDEXk7WeH/RLnnVXWdqi5U1YVtbW1jO7lRpGwev6rn
+P1lYeQcv4V6jEHkhD/dH4msntHqYP4kMEtVT4hIF/BDYK733DWq2isi04FHROT3qvpo8Qt4/xSW
A8yaNQsYCPVEcXG3vb2dffsG/t/29PTQ3l76/1ZE3gB8DXiXqh4auxmOPWXz+HO32ft0aAlz/EY5
ctdP8ujgxyHFz9XfC8wseNzhjeVR1WOqesL7+SGgUUSmeY97ve8HgfvJho5KKOdKoxzqWbRoETt3
7mTPnj2kUik2bNjAkiVLBm0jIrOAHwC3qOofqjLRMaRsVk+usJZPh2aO3yhL7vpJ5IQ/3I7fj6I+
AcwVkQtEpAlYCjxQuIGIzBDJdi0QkSu91z0kIuNFZKI3Ph64Htjud3JRXtyNx+OsWbOGxYsXc/HF
F3PzzTezYMEC1q5dC5CL13wWOBv46ulkTdUTaTeNo86IHb/F+I2y5K6f/iODH4eUYUM9qpoRkQ8D
m4EG4OuqukNEVnjPrwXeD6wUkQzQDyxVVRWRc4D7vf8JceDbqrrJ7+SSmegKP0BXVxddXV2Dxlas
WMHKlSv7AFT1g8AHqzG3sSbXdrFU+IP32wVoNsdvFJK7fhJHBj8OKb5i/F745qGisbUFP68B1pTZ
bzdw2jcV5fL4oxjqMQaTa7tYUrIhHUz4E+lcqMeuKaOAvPB7oR6rx1890hG/c9cYoHLbxdN0/Fay
wSgkd/30R8Px17Si5tM545bOGXXyjn+kMX67gcsoR2NxqCfcMf6avvqjnM5pDKay8AfL6rGSDUZZ
ikM9ltVTPVIRX9w1BsgJf8kNXOb4jdGgoTirx0I9VSMX6rHFXSMn/CUlG4LG+C2d0yhHLJYVfwv1
VB9b3DVyVHT8QbN6Mg7xmBC3a8ooJt4y4PhDXrKhpq/+fFlmc2eRp3KMP7jjN7dvlCVujr8myIV6
4jHL6ok6+Ru4it+QuRi/75INri3sGuVpbAHNao4t7lYRx806fhN+I+E5+4pZPb6LtDnm+I3yFH5q
NMdfPXLC32DCH3kql2zIZfX4v4HLyjUYZSkUe8vqqR6uKjEBr9aPEWEqxvjT/RBrhJg/MTfHb1Qk
F96JxaFhtCrW1yY1/Q7IuGpu3wCGuXM3gDszx29UJOf4Q+72ocaF33WVmLl9g6zwC0JjrHHwE5lE
oHhsMmOO36hATvBDHt+HGhd+x1Vb2DWAge5bJWG/gG3yEmnL6jEqkKvXE/KMHqhx4c+4SsyE36BC
v104DcdvefxGBczx1wauWozfyJJyUqXlGuA0YvwW6jEqkBd+i/FXFQv1GDkSTqK840/3BxN+C/UY
lchdRyFvwgJ1IPy2uGtAhUbrYI7fGD0sq6c2cCyd0/BIOsnScg3gLe6a4zdGgVySgAl/dXEsxm94
JDPJCo4/EeiNmjDHb1TCHH9tYI7fyDEaWT2Oq6QdtX67Rnksq6c2cFylwWL8BlnhL5vVk074zrvO
dd9qaazpy96oFvnFXcvjryquWh6/kWU0HL913zKGxBx/bZBxLJ3TyJK7c7eEAFk9Sa+jm9XqMcpi
efy1QbY6pwm/MZTw9/vO6kmkLdRjDEGjCX9NYIu7Ro6ywu9kwM0Ed/y2uGuUwxx/bRD1ssybNm1i
3rx5dHZ2snr16pLnJcs9IrJLRJ4RkcurMM0xIeWkSvP4naBNWMzxG0MQoTt3a7rbQJRr9TiOw6pV
q3jkkUfo6Ohg0aJFLFmyhPnz5xdu9i5grvd1FXCv931E3PPdj7Lx6Gb64kJbRrlx0mL+7qYvV238
7u98lKST5N+f/ToPPvVv+fGnfvwvvBHQn3yGVx65h32X/wOLlvwNP3yql7s2P8/LR/o5b3Ir/7B4
HgBffLAbgI9/7xn+8d3z+dM3to/0VBlh4sVfZ78/8lnY8q9w3WfhDTdXd05nCFHVas+hhIULF+rW
rVtZuu4xXBe+s+JN1Z7SmPPYY49x5513snnzZgC+9KUvAfCpT30KEdmmqgtF5F+AX6jqegAReR64
VlX3V3rd3LmtxD3f/SjfOrGZRGzAFTe7LgtTU9ja9BrJqowfIVlgAFpcl784NYsVB5+gRdL58X5t
4v6Zn+DzexeQ8DJ4AOKxbBe3tDNwrbc2NvCl973exN/I8sx34IEPD7TyhGxa55/cUzfin9MFP9vW
9Gde141uv93e3l5mzpyZf9zR0UFvb2/xZu3AvoLHPd7YabPx6GDRB0jGYvy65eggUR7b8cHXQCIW
46HmFweJPkCrpHjbS/cOEn2AjMsg0QfoTzvctfn5MmfAiCQ/+/xg0YdsAcCffb468znD1LTwZ1w3
ssI/mojIchHZKiJb+/r6hty2L17hfFf6ZFil8QMVFmjPk0PlX6cMLx/p972tEXKO9gQbr3NqWvgd
JbI3cLW3t7Nv34CZ7+npob29xMz3AjMLHnd4Y4NQ1XWqulBVF7a1tQ35e9sy5YW20oVSrfEZ3kJt
Mfs5u8IepZw3Ofx3aBo+mdQRbLzOqWnhdyNcj3/RokXs3LmTPXv2kEql2LBhA0uWLCne7AHgVi+7
52rg6FDxfT/cOGkxLe7gUEmL6/LWVFtNjXelO+nXwXfy9msTvz7/Q7QW3aDVGBMaGwZfR62NDflF
X8Pgus+WlmpobM2Oh5CaFv5MhOvxx+Nx1qxZw+LFi7n44ou5+eabWbBgAWvXrgXI2faHgN3ALuBf
gQ+N9Pf+3U1f5pYJi5medhFVpqddbpmwmDXLf15T43+/8kdsv+KLHKANV4UDtLH9ii9y87KP8aX3
vZ72ya0I0D65lbtuupS73n/poDFb2DUG8Yabswu5k2YCkv1eRwu7QfGV1SMiNwB3Aw3A11R1ddHz
1wIbgT3e0A9U9fN+9i1HLvNk8f9+lNnTxvEvt/haqI4MQVbvixkuq8cwjPokiC4Mm8cvIg3AV4B3
ks0aeUJEHlDV7qJNf6Wq7znNfcviqBKP1fSHEsMwjLrDj6peCexS1d2qmgI2ADf6fP2R7JttvRjR
GL9hGMaZwo/w+80Vf7NXNuBhEVkQcN+yZOvx+93aMAzD8MNolWx4EpilqidEpAv4IdkyAr4RkeXA
coBZs2YBcO28Nl7XNmGUpmgYhmGAP+EfNldcVY8V/PyQiHxVRKb52bdgv3XAOsguQAJ8/sZLfEzP
MAzDCIKfUM8TwFwRuUBEmoClZPPH84jIDJFs3qWIXOm97iE/+xqGYRhjy7COX1UzIvJhYDPZlMyv
q+oOEVnhPb8WeD+wUkQyQD+wVLN5omX3PUPHYhiGYfjAV4xfVR8ie7NQ4djagp/XAGv87msYhmFU
D0uSNwzDiBgm/IZhGBHDhN8wDCNimPAbhmFEDBN+wzCMiFGTPXdFpA/Y6z2cBrxaxenUCoXn4XxV
HbqjSgWKzm2Q3xl2onSsEK3jjcqx+taFmhT+QkRk6+mWIA4T1TgPUTr3UTpWiNbxRulY/WKhHsMw
jIhhwm8YhhEx6kH411V7AjVCNc5DlM59lI4VonW8UTpWX9R8jN8wDMMYXerB8RuGYRijSM0Kv4jc
ICLPi8guEflktecz2ojI10XkoIhsLxibKiKPiMhO7/uUguc+5Z2L50VkccH4FSLyrPfcPbny2KMw
v9Ce/6Dnvp4RkZki8nMR6RaRHSJyhzceuuMVkRYR2SIiv/OO9XPeeOiOdaTUpPAXNGl/FzAf+DMR
mV/dWY069wE3FI19EviZqs4FfuY9xjv2pcACb5+veucI4F7gr8l2PJtb5jUDE4Hzfx8+z30IyAAf
U9X5wNXAKu9vGcbjTQLvUNVLgcuAG0TkasJ5rCOiJoWfETZprwdU9VHgcNHwjcA3vJ+/AfxpwfgG
VU2q6h5gF3CliJwLnKWqv/X6H3yzYJ+REOrzH/Dc1zWqul9Vn/R+Pg48R7bvdeiOV7Oc8B42el9K
CI91pNSq8I+oSXsdc46q7vd+PgCc4/1c6Xy0ez8Xj4+UKJ7/Suc+NIjIbOCNwOOE9HhFpEFEngYO
Ao+oamiPdSTUqvBHHs/BW8pVFQjjuReRCcD3gb8v7JEN4TpeVXVU9TKy/b2vFJFLip4PzbGOhFoV
ft9N2kPGK174Bu/7QW+80vno9X4uHh8pUTz/lc593SMijWRF/z9V9QfecGiPF0BVjwA/J7uWE+pj
PR1qVfij2qT9AeAD3s8fADYWjC8VkWYRuYDsIu4W7+PrMRG52svmubVgn5EQxfNf6dzXNd518W/A
c6r65YKnQne8ItImIpO9n1uBdwK/J4THOmJUtSa/gC7gD8ALwKerPZ8zcHzrgf1AmmwM/XbgbLJZ
BzuBnwJTC7b/tHcungfeVTC+ENjuPbcG76Y8O/+jd+7r+Qu4hmxo4xngae+rK4zHC7wBeMo71u3A
Z73x0B3rSL/szl3DMIyIUauhHsMwDOMMYcJvGIYRMUz4DcMwIoYJv2EYRsQw4TcMw4gYJvyGYRgR
w4TfMAwjYpjwG4ZhRIz/D8E5aSBQnybUAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The code above is doing steepest ascent in the gradient of the log
likelihood.  Do we have a better way of doing this gradient ascent?</p>
<p>Hey, how about using Moller's Scaled Conjugate Gradient again?  Just
have to define the function being optimized and its gradient.  The
function to be optimized should be the negative of the log likelihood,
because SCG is designed to minimize the function.  And the gradient
function must also include this negative.  But with these negatives,
SCG will work fine for optimizing the weights in a linear logistic
regression classifier.</p>
<p>This is left for you to do.  You will get clues about how to do this from the neural network implementation of nonlinear logistic regression in the next set of notes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are definitions of the log likehood and its gradient again.
$$
      \begin{align*}
      LL(\wv) & = \sum_{n=1}^N \sum_{k=1}^K t_{n,k} \log g_k(\xv_n)\\
      \grad_{\wv_j} LL(\wv)  & = \sum_{n=1}^N \xv_n (t_{n,j} - g_j(\xv_n))
      \end{align*}
$$</p>
<p>or, as matrices, and using the mean log likelihood,</p>
$$
    \begin{align*}
    Y &= g(\Xv)\\
    LL(\wv) & = \text{np.mean}(T \cdot \log Y , \text{axis}=0) \\
      \grad_{\wv_j} LL(\wv) & =  \Xv^T (T - Y) \;/\; (N\,K)
    \end{align*}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scaledconjugategradient</span> <span class="k">as</span> <span class="nn">scg</span>

<span class="k">def</span> <span class="nf">runParkLogReg2</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainFraction</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">header</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="n">names</span> <span class="o">=</span> <span class="n">header</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">f</span> <span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">))</span>

    <span class="n">targetColumn</span> <span class="o">=</span> <span class="n">names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
    <span class="n">XColumns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">XColumns</span><span class="p">,</span> <span class="n">targetColumn</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="n">XColumns</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="n">targetColumn</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># to keep 2-d matrix form</span>
    <span class="n">names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;status&quot;</span><span class="p">)</span>

    <span class="n">healthyI</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">parkI</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">T</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">healthyI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">healthyI</span><span class="p">)</span>
    <span class="n">parkI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">parkI</span><span class="p">)</span>

    <span class="n">nHealthy</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">trainFraction</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">healthyI</span><span class="p">))</span>
    <span class="n">nPark</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">trainFraction</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">parkI</span><span class="p">))</span>
    <span class="n">rowsTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">healthyI</span><span class="p">[:</span><span class="n">nHealthy</span><span class="p">],</span> <span class="n">parkI</span><span class="p">[:</span><span class="n">nPark</span><span class="p">]))</span>
    <span class="n">Xtrain</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">rowsTrain</span><span class="p">,:]</span>
    <span class="n">Ttrain</span> <span class="o">=</span> <span class="n">T</span><span class="p">[</span><span class="n">rowsTrain</span><span class="p">,:]</span>
    <span class="n">rowsTest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">healthyI</span><span class="p">[</span><span class="n">nHealthy</span><span class="p">:],</span> <span class="n">parkI</span><span class="p">[</span><span class="n">nPark</span><span class="p">:]))</span>
    <span class="n">Xtest</span> <span class="o">=</span>  <span class="n">X</span><span class="p">[</span><span class="n">rowsTest</span><span class="p">,:]</span>
    <span class="n">Ttest</span> <span class="o">=</span>  <span class="n">T</span><span class="p">[</span><span class="n">rowsTest</span><span class="p">,:]</span>

    <span class="n">means</span><span class="p">,</span><span class="n">stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Xtrains</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">)</span>
    <span class="n">Xtests</span> <span class="o">=</span> <span class="n">standardize</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">)</span>
    
    <span class="n">Xtrains1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xtrains</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xtrains</span><span class="p">))</span>
    <span class="n">Xtests1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xtests</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span> <span class="n">Xtests</span><span class="p">))</span>

    <span class="c1"># New stuff for linear logistic regression</span>

    <span class="n">TtrainI</span> <span class="o">=</span> <span class="n">makeIndicatorVars</span><span class="p">(</span><span class="n">Ttrain</span><span class="p">)</span>
    <span class="n">TtestI</span> <span class="o">=</span> <span class="n">makeIndicatorVars</span><span class="p">(</span><span class="n">Ttest</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">TtrainI</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">loglikelihood</span><span class="p">(</span><span class="n">warg</span><span class="p">,</span><span class="n">K</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">warg</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtrains1</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
        <span class="c1"># print(w)</span>
        <span class="k">return</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">TtrainI</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">gradientloglikelihood</span><span class="p">(</span><span class="n">warg</span><span class="p">,</span><span class="n">K</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">warg</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
        <span class="c1"># print(&#39;w&#39;,w)</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">Xtrains1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtrains1</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
        <span class="c1"># print(&#39;Y&#39;,Y[:10,:])</span>
        <span class="c1"># print(&#39;Xtrains1&#39;,Xtrains1[:5,:])</span>
        <span class="c1"># print(&#39;TtrainI&#39;,TtrainI[:5,:])</span>
        <span class="c1"># print(&#39;dot&#39;,np.dot(Xtrains1.T,(Y-TtrainI)[:,:-1]))</span>
        <span class="c1"># print(&#39;N&#39;,N,&#39;K&#39;,K)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xtrains1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="o">-</span><span class="n">TtrainI</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtrains1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">TtrainI</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">resultSCG</span> <span class="o">=</span> <span class="n">scg</span><span class="o">.</span><span class="n">scg</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">loglikelihood</span><span class="p">,</span> <span class="n">gradientloglikelihood</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">nIterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ftracep</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">wresult</span> <span class="o">=</span> <span class="n">resultSCG</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">wresult</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>

    <span class="n">logregOutput</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtrains1</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">predictedTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logregOutput</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">logregOutput</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">Xtests1</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="n">predictedTest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logregOutput</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LogReg SCG: Percent correct: Train </span><span class="si">{:.3g}</span><span class="s2"> Test </span><span class="si">{:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTrain</span><span class="p">,</span><span class="n">Ttrain</span><span class="p">),</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTest</span><span class="p">,</span><span class="n">Ttest</span><span class="p">)))</span>

    <span class="c1"># Previous QDA code</span>
    
    <span class="n">Ttr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ttrain</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">mu1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cov1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">Ttr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ttrain</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">mu2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cov2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">[</span><span class="n">Ttr</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="n">d1</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">,</span><span class="n">mu1</span><span class="p">,</span><span class="n">cov1</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">nHealthy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtrains</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">,</span><span class="n">mu2</span><span class="p">,</span><span class="n">cov2</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">nPark</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">predictedTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">d1</span><span class="p">,</span><span class="n">d2</span><span class="p">)),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">d1t</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtests</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">,</span><span class="n">mu1</span><span class="p">,</span><span class="n">cov1</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">nHealthy</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">d2t</span> <span class="o">=</span> <span class="n">discQDA</span><span class="p">(</span><span class="n">Xtests</span><span class="p">,</span><span class="n">means</span><span class="p">,</span><span class="n">stds</span><span class="p">,</span><span class="n">mu2</span><span class="p">,</span><span class="n">cov2</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">nPark</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nHealthy</span><span class="o">+</span><span class="n">nPark</span><span class="p">))</span>
    <span class="n">predictedTest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">d1t</span><span class="p">,</span><span class="n">d2t</span><span class="p">)),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   QDA: Percent correct: Train </span><span class="si">{:.3g}</span><span class="s2"> Test </span><span class="si">{:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTrain</span><span class="p">,</span><span class="n">Ttrain</span><span class="p">),</span><span class="n">percentCorrect</span><span class="p">(</span><span class="n">predictedTest</span><span class="p">,</span><span class="n">Ttest</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">runParkLogReg2</span><span class="p">(</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>LogReg SCG: Percent correct: Train 89.1 Test 82.1
   QDA: Percent correct: Train 75.6 Test 74.4
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">runParkLogReg2</span><span class="p">(</span><span class="s1">&#39;parkinsons.data&#39;</span><span class="p">,</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>LogReg SCG: Percent correct: Train 92.9 Test 76.9
   QDA: Percent correct: Train 75.6 Test 74.4
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
 


    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="http://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://developer.rackspace.com/?nbviewer=awesome">Rackspace</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/4f5d1d8a2539c1c8dc92873d3a775d34f0a3d417">
                  4f5d1d8
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/5.1.1">
      5.1.1
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Sun, 26 Mar 2017 22:02:58 UTC' title='Sun, 26 Mar 2017 22:02:58 UTC'>(Sun, 26 Mar 2017 22:02:58 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="https://unpkg.com/jupyter-js-widgets@2.0.*/dist/embed.js"></script>
  <script src="/static/components/bootstrap/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js?v=b0a311ea668f8e768ea375f4a7abb81c"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js?v=f3a1bae118315d0c234afc74dc6aab71"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-52617120-5', 'auto');
    ga('send', 'pageview');
  </script>
  
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js?v=89f87298ad94aa1e6b92f42eb66da043"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>
  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>