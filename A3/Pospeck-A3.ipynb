{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Neural Network Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bradley Pospeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare linear and neural network models applied to a data set of your choice.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [nnA3.tar](http://www.cs.colostate.edu/~anderson/cs480/notebooks/nnA3.tar) and extract its contents, which are\n",
    "\n",
    "* `neuralnetworks.py`\n",
    "* `scaledconjugategradient.py`\n",
    "* `mlutils.py`\n",
    "\n",
    "as discussed in lecture. \n",
    "\n",
    "Write the following functions that train and evaluate linear and neural network models.\n",
    "\n",
    "* `model = trainLinear(X,T,parameters)`\n",
    "* `error = evaluateLinear(model,X,T)`\n",
    "* `model = trainNN(X,T,parameters)`\n",
    "* `error = evaluateNN(model,X,T)`\n",
    "\n",
    "Write a new and improved version of the function we have been using to partition data into folds and combine them into training, validation and testing subsets.  Call this new version `trainValidateTestKFolds`.  Instead of returning data subsets, it applies train and evaluate functions to the subsets.  It uses the validation subset to determine the best model parameter values.  It must implement the following algorithm. The part up to \"COMPLETE THIS FUNCTION...\" is given in Python.  Do not change it.  Do write the rest of the function.\n",
    "\n",
    "```\n",
    "def trainValidateTestKFolds(trainf,evaluatef,X,T,parameterSets,nFolds,\n",
    "                            shuffle=False,verbose=False):\n",
    "    # Randomly arrange row indices\n",
    "    rowIndices = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(rowIndices)\n",
    "    # Calculate number of samples in each of the nFolds folds\n",
    "    nSamples = X.shape[0]\n",
    "    nEach = int(nSamples / nFolds)\n",
    "    if nEach == 0:\n",
    "        raise ValueError(\"partitionKFolds: Number of samples in each fold is 0.\")\n",
    "    # Calculate the starting and stopping row index for each fold.\n",
    "    # Store in startsStops as list of (start,stop) pairs\n",
    "    starts = np.arange(0,nEach*nFolds,nEach)\n",
    "    stops = starts + nEach\n",
    "    stops[-1] = nSamples\n",
    "    startsStops = list(zip(starts,stops))\n",
    "    # Repeat with testFold taking each single fold, one at a time\n",
    "    results = []\n",
    "\n",
    "    # COMPLETE THIS FUNCTION BY IMPLEMENTING THE FOLLOWING STEPS.\n",
    "    \n",
    "    # For each test fold\n",
    "        for parmSet in parameterSets:  # For each set of parameter values, called parmSet\n",
    "            # Find best set of parameter values\n",
    "            # For each validate fold (except when same as test fold)\n",
    "                # Use trainf to fit model to training data using parmSet\n",
    "                # Calculate the error of this model by calling evaluatef with \n",
    "                #  the model and validation data\n",
    "            # Calculate the mean of these errors.\n",
    "            # If this error is less than the previously best error for parmSet, \n",
    "            # update best parameter values and best error\n",
    "        # Make a new set of training data by concatenating the training and \n",
    "        # validation data from previous step.\n",
    "        # Retrain, using trainf again, to fit a new model to this new training data.\n",
    "        # Calculate error of this new model on the test data, and also on the new \n",
    "        #  training data.\n",
    "        # Construct a list of the best parameter values with this training error, \n",
    "        #  the mean of the above valdiation errors, and the testing error\n",
    "        # Print this list if verbose == True\n",
    "        # Append this list to a result list\n",
    "    # Return this result list\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `parameters` argument to the `trainLinear` function is just the value of $\\lambda$. For the `trainNN` function it must specify the hidden layer structure and the number of Scaled Conjugate Gradient iterations.  Here are some examples:\n",
    "```\n",
    "model = trainNN(X,T,[5, 100])       # Single hidden layer of 5 units, trained \n",
    "                                    # for 100 iterations\n",
    "model = trainNN(X,T,[[10,10], 200]) # Two hidden layers, 10 units each, \n",
    "                                    # trained for 200 iterations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-0755e613f270>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0755e613f270>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    for parmSet in parameterSets:  # For each set of parameter values, called parmSet\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def trainValidateTestKFolds(trainf,evaluatef,X,T,parameterSets,nFolds,\n",
    "                            shuffle=False,verbose=False):\n",
    "    # Randomly arrange row indices\n",
    "    rowIndices = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(rowIndices)\n",
    "    # Calculate number of samples in each of the nFolds folds\n",
    "    nSamples = X.shape[0]\n",
    "    nEach = int(nSamples / nFolds)\n",
    "    if nEach == 0:\n",
    "        raise ValueError(\"partitionKFolds: Number of samples in each fold is 0.\")\n",
    "    # Calculate the starting and stopping row index for each fold.\n",
    "    # Store in startsStops as list of (start,stop) pairs\n",
    "    starts = np.arange(0,nEach*nFolds,nEach)\n",
    "    stops = starts + nEach\n",
    "    stops[-1] = nSamples\n",
    "    startsStops = list(zip(starts,stops))\n",
    "    # Repeat with testFold taking each single fold, one at a time\n",
    "    results = []\n",
    "\n",
    "    # COMPLETE THIS FUNCTION BY IMPLEMENTING THE FOLLOWING STEPS.\n",
    "    \n",
    "    # For each test fold\n",
    "        for parmSet in parameterSets:  # For each set of parameter values, called parmSet\n",
    "            # Find best set of parameter values\n",
    "            # For each validate fold (except when same as test fold)\n",
    "                # Use trainf to fit model to training data using parmSet\n",
    "                # Calculate the error of this model by calling evaluatef with \n",
    "                #  the model and validation data\n",
    "            # Calculate the mean of these errors.\n",
    "            # If this error is less than the previously best error for parmSet, \n",
    "            # update best parameter values and best error\n",
    "        # Make a new set of training data by concatenating the training and \n",
    "        # validation data from previous step.\n",
    "        # Retrain, using trainf again, to fit a new model to this new training data.\n",
    "        # Calculate error of this new model on the test data, and also on the new \n",
    "        #  training data.\n",
    "        # Construct a list of the best parameter values with this training error, \n",
    "        #  the mean of the above valdiation errors, and the testing error\n",
    "        # Print this list if verbose == True\n",
    "        # Append this list to a result list\n",
    "    # Return this result list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "```\n",
    "X = np.arange(100).reshape((-1, 1))\n",
    "T = np.abs(X -50) + X\n",
    "\n",
    "result = trainValidateTestKFolds(trainLinear, evaluateLinear ,X, T, range(0,101,10), nFolds=5, shuffle=False)\n",
    "                                 \n",
    "print('Linear Model\\n{:^10s} {:>10s} {:>10s} {:>10s}'.format('lambda', 'train', 'validate', 'test RMSE'))\n",
    "for x in result:\n",
    "    print('{:^10.2f} {:>10.3f} {:10.3f} {:10.3f}'.format(*x))\n",
    "```\n",
    "should result in\n",
    "```\n",
    "Linear Model\n",
    "  lambda        train   validate  test RMSE\n",
    "  30.00        13.576     16.028     19.301\n",
    "  100.00       22.438     20.407     20.099\n",
    "  30.00        14.419     16.542     25.194\n",
    "  70.00        21.098     24.589      9.615\n",
    "  100.00       13.036     12.768     55.356\n",
    "```\n",
    "\n",
    "An example of fitting a neural network to this data is\n",
    "```\n",
    "import itertools\n",
    "parms = list(itertools.product([2, 5, 10, 20, [5, 5], [10, 2, 10]], [10, 20, 100, 500]))\n",
    "result = trainValidateTestKFolds(trainNN, evaluateNN, X, T, parms, nFolds=5, shuffle=False)\n",
    "print('NN Model\\n{:>30s} {:>10s} {:>10s} {:>10s}'.format('(Hidden Units, Iterations)', 'train', 'validate', 'test RMSE'))\n",
    "for x in result:\n",
    "    print('{:>30s} {:10.3f} {:10.3f} {:10.3f}'.format(str(x[0]), *x[1:]))\n",
    "```\n",
    "should result in something like \n",
    "```\n",
    "NN Model\n",
    "    (Hidden Units, Iterations)      train   validate  test RMSE\n",
    "            ([10, 2, 10], 500)      0.289      1.751      0.319\n",
    "                 ([5, 5], 500)      0.150      2.066      0.259\n",
    "                     (20, 500)      0.045      1.174      2.584\n",
    "                     (20, 500)      0.250      7.903      1.258\n",
    "                     (20, 500)      0.162      2.330      5.648\n",
    "```\n",
    "Your results will differ, due to the initial random values for the neural network's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Pick a data set that is interesting to you.  Explain why you picked it.  Investigate the data with some plots and describe what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Investigate the use of a linear model with various $\\lambda$ values for your chosen data.  Then investigate the use of a neural network model on the same data for various sizes of hidden layers and numbers of iterations.\n",
    "Discuss the results obtained, including the error values and the parameter values that result in the best performance.\n",
    "\n",
    "Apply the `trainValidateTestKFolds` function, print the results, and discuss them.  How much variation is there in the best parameter values across different test folds?  Does the complexity of the models, in terms of the best parameters found, make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Your notebook will be run and graded automatically. Download [A3grader.tar](http://www.cs.colostate.edu/~anderson/cs480/notebooks/A3grader.tar) and extract `A3grader.py` from it. Run the code in the following cell to demonstrate an example grading session.  You should see a perfect score of 80/100 if your functions are defined correctly.  The remaining 20% will be based on the instructors reading of your notebooks.  We will be looking for how well the method is explained in text with some LaTeX math, and how well the results are summarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing: result = trainValidateTestKFolds(trainLinear,evaluateLinear,X,T,\n",
      "                  range(0,101,10),nFolds=5,shuffle=False)\n",
      " Result is\n",
      "    10   3.158   3.306   2.414\n",
      "    20   4.368   4.017   3.641\n",
      "    10   3.245   3.343   5.03\n",
      "    20   4.448   4.856   2.024\n",
      "    20   2.426   2.377   10.89\n",
      "20/20 points. First column, of best lambda values, is correct.\n",
      "20/20 points. Columns of RMSE values are correct.\n",
      " Running:\n",
      "   import itertools\n",
      "   parms = list(itertools.product([[5],[5,5],[2,2,2]], [10,50,100,200]))\n",
      "   te = []\n",
      "   for rep in range(5):\n",
      "       result = trainValidateTestKFolds(trainNN,evaluateNN,X,T,\n",
      "                                        parms,\n",
      "                                        nFolds=4,shuffle=False)\n",
      "       resulte = np.array([r[1:] for r in result])\n",
      "       meanTestRMSE = resulte[:,-1].mean()\n",
      "       print('     ',meanTestRMSE)\n",
      "       te.append(meanTestRMSE)\n",
      "      2.10077032973\n",
      "      2.00326657671\n",
      "      2.15693009859\n",
      "      2.48018047289\n",
      "      1.15109968332\n",
      "40/40 points. Mean test RMSE is less than 5.\n",
      "\n",
      "Download Grade is 80/100\n",
      "Up to 20 more points will be given based on the qualty of your descriptions of the method and the results.\n"
     ]
    }
   ],
   "source": [
    "%run -i \"A3grader.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not include this section in your notebook.\n",
    "\n",
    "Name your notebook ```Lastname-A3.ipynb```.  So, for me it would be ```Anderson-A3.ipynb```.  Submit the file using the ```Assignment 3``` link on [Canvas](https://colostate.instructure.com/courses/41327).\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct behavior of the required functions,\n",
    "  * readability of the notebook,\n",
    "  * effort in making interesting observations, and in formatting your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
